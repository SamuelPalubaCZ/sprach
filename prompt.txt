Design of a Numbers Station Transmission Simulator

Introduction

A numbers station is a shortwave radio station known for broadcasting sequences of numbers, often read aloud in a mechanized voice ￼. These transmissions are believed to be encrypted messages for intelligence agents ￼. The goal of this web application is to simulate a Sprach/Morse (voice) numbers station transmission entirely in the browser. It will allow users to input a message, encode it into number groups, and play it back using prerecorded audio clips (digits and codewords like “Achtung”, “Trennung”, “Ende”). The app will be static (HTML, CSS, JavaScript) and fully offline-capable so it can be hosted on GitHub Pages.

Message Encoding Features

Input and Cipher Options

Users can enter a plaintext message (letters A–Z, digits 0–9, and possibly spaces/punctuation). The app will provide encoding options:
	•	A1Z26 Cipher: A simple substitution where each letter is replaced by its position in the alphabet (A=1, B=2, …, Z=26) ￼ ￼. For example, “HELLO” becomes 8 5 12 12 15 under A1Z26 ￼. Non-letter characters (spaces, digits) can be handled by preserving them or mapping to a placeholder (e.g. 0 for space, etc.), but for simplicity the app may restrict input to alphanumeric characters. After converting each letter to a number, the numeric string will be concatenated.
	•	Straddling Checkerboard Cipher: A more sophisticated method to convert text to digits. In a straddling checkerboard, common letters get a single-digit code and other characters get two-digit codes ￼. Essentially, a checkerboard grid is set up with digits 0–9 as column headers, and two designated “straddle” digits that also serve as row labels ￼. High-frequency letters (like E, T, A, O, N, I, R in English) are placed in the top row to get one-digit codes, while remaining letters use two digits (row label + column) ￼. This produces a numeric ciphertext that’s more compressed than A1Z26. The app can use a default checkerboard (for example, the one used in the famous VIC cipher or a configurable key) – but even a fixed configuration will demonstrate the concept. When the user selects “Straddling Checkerboard”, the plaintext is encoded into a string of digits according to the checkerboard mapping. (If needed, a space or other symbols could be encoded with special codes like  / for space as “Trennung”, but the core focus is letters/digits.)
	•	OTP (One-Time Pad) Option: For added realism, the app can apply a one-time pad to the numeric message after applying the above cipher. Historically, numbers station messages were encrypted with one-time pads (mod 10 addition on each digit) to be unbreakable ￼ ￼. If the OTP option is enabled, the user provides a numeric key of the same length as the encoded message (or the app can generate a random key). Each digit of the numeric message is then combined with the corresponding key digit modulo 10 to produce the final transmitted digits ￼. For example, if the plaintext code (after A1Z26 or checkerboard) is 65417 and OTP key is 47757, the encrypted output would be (6−4, 5−7, 4−7, 1−5, 7−7) mod 10 = 17760 (depending on whether we subtract or add the key; both addition and subtraction mod 10 are effectively equivalent in strength ￼). The app will use the convention of $P + K$ (plaintext plus key mod 10) to encrypt and $C − K$ mod 10 to decrypt ￼, or simply $C = (P + K) mod 10$. OTP encryption ensures the numeric message appears random. If OTP is off, the numeric groups are unencrypted.
	•	XOR Utility (ASCII/Hex): In addition to the number-station-specific ciphers, the app will include a general XOR encryption/decryption tool for completeness. This feature lets users XOR any two data inputs, either as ASCII text or as hex strings. The UI will have a mode toggle for “ASCII” or “Hex” input. For ASCII mode, the algorithm will take each character’s char code from the plaintext and XOR it with a repeating key’s char codes ￼. For hex mode, the input and key are interpreted as sequences of bytes (pairs of hex digits) and XORed byte-by-byte. The same function can be used to encrypt or decrypt since XOR is its own inverse ￼ (applying the same key again restores the original text). For example, XOR-ing the ASCII string “XOR” with key 0x86 (134) yields a scrambled text ÞÉÔ, and XOR-ing that result with the same key reverts to “XOR” ￼ ￼. This XOR tool is separate from the one-time-pad numeric cipher (though conceptually OTP could be seen as XOR on base-10 digits or on binary data). It will be useful for users who want to experiment with simple symmetric encryption in hex or text form.

Formatting into 5-Digit Groups

Numbers station messages are traditionally sent as groups of fixed length (often 5 digits) for readability and to conceal message length. Our app will automatically format the encoded numeric string into 5-digit groups:
	•	Grouping: As the user encodes the message (with or without OTP), the output will be split into blocks of 5 digits separated by spaces. For instance, plaintext “HELLO” (A1Z26 -> 08 05 12 12 15) might yield groups 08051 21215. If the final block is not full, the app will pad it. Padding can be done with a neutral filler (like random digits or a known dummy pattern). Historically, null or random letters (like “X” or “nulls”) were added to fill the last group in cipher messages. We will simply append random digits 0–9 to complete the last 5-digit group if needed. The total number of groups is then counted.
	•	Count Calculation: The app will display the group count (the number of 5-digit groups) and use it during transmission. For example, if the encoded message results in 12 groups of 5 digits, the count is 12 (which might be spoken as “1 2” in the transmission). In some historic formats, this count is given as a two-digit number (e.g., 12 -> “1 2” or “12” depending on convention). Our simulation will likely speak each digit separately for clarity. The group count is important for the recipient to know when the message ends and to verify they received all groups.

The UI will show the encoded output (grouped digits) and the group count. It may also show a plaintext preview (for example, if a one-time-pad key is applied, it could show the intermediate unencrypted numeric text for reference, or if decrypting, show the recovered plaintext). However, by default, only the final transmitted groups and count are needed for playback.

Example Workflow
	1.	User Input: “HELLO”
	2.	Select Cipher: A1Z26, OTP off.
	3.	Encoding: “HELLO” -> 8 5 12 12 15 ￼ -> numeric string "85121215".
	4.	Grouping: "85121215" -> pad to 10 digits (need 10 for two full groups of 5). If we pad with random, e.g. add “37” to end to make "8512121537".
	5.	5-digit Groups: "85121 21537". Group count = 2.
	6.	The app shows output: 85121 21537 (2 groups).

During playback, it would announce: “Achtung [ID] Trennung 02 … 85 121 21 537 … Ende.” (with each digit read out separately; see next section for format).

Note: If OTP were on, an additional step would add a key e.g. key=31415927 (random digits) to produce the encrypted groups. The original plaintext groups might still be shown for reference if decrypting.

Audio Playback System

A core part of the simulation is playing audio clips for each digit and control word in correct sequence and timing, replicating an authentic numbers station broadcast.

Voice Packs and Audio Assets

We will include pre-recorded .wav files for the digits “0” through “9” and for the procedural words “Achtung”, “Trennung”, and “Ende”. In fact, East German number stations used exactly these 13 words in their voice transmissions ￼, with Achtung meaning “Attention” (start of message), Trennung meaning “Separation” or “Break”, and Ende meaning “End” (end of transmission). The application will support multiple language/voice packs: e.g., a German voice (commonly heard in recordings), an English voice, Spanish voice, etc. Each voice pack will be a folder containing at least the 10 digit audio files and the special words (some languages may have their own equivalents: e.g. Spanish might use “Atención” for Achtung, “Separación” for Trennung, “Fin” for Ende, if we have those recordings).

Voice Pack Selection: The app can have a dropdown or list of available voice packs. These packs can be defined in a configuration object or JSON file that lists the pack name and the file naming scheme/path. For example:

voicePacks: [
  { "name": "German (Female)", "path": "voices/german_female/" },
  { "name": "Spanish (Female)", "path": "voices/spanish_female/" }
]

All audio files will be stored locally in these folders so that GitHub Pages can serve them. When the user selects a pack, the app will attempt to load 0.wav–9.wav, achtung.wav, trennung.wav, ende.wav from that folder. If any file is missing in a pack, the app will fall back to a default voice (e.g., the German pack) for that particular sound. This ensures continuity (for instance, if a custom pack only provides digits 0-9, we might still use the default “Achtung” clip if not provided).

Preloading Audio: To avoid gaps or latency during playback, all necessary audio clips will be preloaded and decoded as soon as the user selects a voice pack (or on app load for the default pack). Using the Web Audio API, we can fetch() each WAV file as an ArrayBuffer and use AudioContext.decodeAudioData to get an AudioBuffer for each digit and word. Preloading small clips in advance is a best practice to ensure smooth playback ￼ ￼, especially since these are short samples (each digit word is under 1 second). By decoding to AudioBuffer upfront, we can schedule their playback precisely with no further disk/network delay. (We’ll also handle the user gesture requirement to start audio contexts – e.g., enabling a “Start Transmission” button that resumes the AudioContext if it’s in suspended state, to comply with browser autoplay policies ￼ ￼.)

Transmission Format and Sequencing

The playback format will emulate known numbers station protocols ￼ ￼:
	•	Prelude: Optionally play an introduction. Some stations began with an interval signal or distinctive tone (e.g., G03 “gongs” ￼) – we may omit this or include a simple repeating tone for realism. More importantly, the transmission typically starts with the word “Achtung” (German for “Attention”) spoken to alert the listener ￼. In some stations, “Achtung” was repeated twice (e.g., “Achtung, Achtung”) ￼. Our app can allow a setting to repeat Achtung twice if desired. After “Achtung”, a 5-digit message identifier or key number might be given, followed by “Trennung”, then the two-digit group count, and “Trennung” again ￼ ￼. For example, a classic format: “Achtung [ID] Trennung [Count]”, repeated twice, before the actual message groups ￼ ￼. If we implement a message ID (which could be a random 5-digit or user-specified), the app will include that. Otherwise, we might skip the ID and just announce the group count. For simplicity, assume we generate a random 5-digit “key ID” each time (to simulate the OTP key page number as was done historically ￼) – the user may not need to input this, it’s mainly cosmetic. So the prelude spoken might be: “Achtung [1 6 3 2 4] Trennung [2 8]” (using the example from a Stasi station ￼ where 16324 was key and 28 groups ￼). The app will automatically insert the appropriate digits for [ID] and [Count] into the audio sequence.
	•	Message Body: After the preamble (which may be repeated twice as some stations did for clarity ￼), the core message groups are transmitted. Each 5-digit group will be read aloud, digit by digit, in a monotone voice. Often, number stations repeated each group twice in a row to ensure it was received correctly ￼. We can provide an option “Repeat groups” that, if enabled, will play each group two times back-to-back (e.g., 76582 76582 40822 40822 ... as in station G03 ￼). The time gap between consecutive digits will be consistent (e.g. perhaps 0.8 seconds per digit sound including the sound length, so if a clip is 0.5s, maybe 0.3s silence after). Between groups, we insert a slightly longer pause or a spoken “Trennung” if that was a practice. In many cases, “Trennung” (meaning “separation”) was not spoken between every group, but used as a procedural separator (for example between the header and the message). We will follow the standard format: use “Trennung” around the boundary of header and message, but not between every group (instead just use a short silence between groups). The user can configure the timing parameters: e.g., digit duration (or gap), inter-group gap, etc., via input sliders to simulate different transmission speeds. We might include a default timing that corresponds to a typical words-per-minute of known devices (e.g., Gerät 32620 allowed adjusting WPM and pitch ￼; we can pick a moderate speed).
	•	Conclusion: After all groups are sent, the station ends the transmission with the word “Ende” (German for “End”) ￼. In our simulation, once “Ende” is played, the transmission is complete. (Some stations then repeated the whole message after a pause, or had a specific sign-off. We may allow an “Repeat Message” option that, if checked, plays the same message again from the start after a pause – effectively transmitting it twice – which was sometimes done). By default, we’ll assume one pass is enough, since we already have optional per-group repetition.

Live Transmission Mode: In addition to encoding a full message and hitting “Play”, the app could support a “live” mode where whatever the user types is immediately queued to be spoken. For example, as the user enters digits or clicks the dialer (see Manual Dialer below), the sounds play with minimal delay. This mode would simulate a live operator transmitting in real-time. Achieving this means handling input events and immediately scheduling or playing the corresponding sound. We must ensure the previous sound is either finished or mix in new sound seamlessly. Using the Web Audio API’s scheduling can help here: we can keep track of the current end of the audio queue (a timestamp), and every time the user inputs a new element, schedule its sound to start at the latest queue end time. If the user types faster than playback, their input just queues up. If they pause, the transmission will pause when it runs out of queued audio until new input arrives. Live mode is advanced, but the architecture (AudioBuffer scheduling) makes it feasible.

Using Web Audio API for Precise Scheduling

To play the sequence of clips seamlessly, we will use the Web Audio API (via AudioContext). Each audio clip (digit or word) will be stored in an AudioBuffer. We will create an AudioBufferSourceNode for each clip we need to play, connect it to the audio context’s destination (or a gain node, see Stop functionality below), and call source.start(scheduledTime) to schedule it. By calculating the start times cumulatively, we can ensure sample-accurate timing (no gaps or overlaps) between clips. This approach leverages Web Audio’s high precision timing ￼ ￼, as opposed to trying to play one clip after another in JavaScript with setTimeout (which would be less accurate).

Timing Calculation: We will maintain a currentTimeOffset that starts at 0. For each item in the transmission sequence (which could be: Achtung, ID digits, “Trennung”, count digits, “Achtung” again if repeating header, etc., then groups…), we determine its duration. We know each AudioBuffer’s duration property in seconds after decoding ￼ ￼. We also can insert configured silences. For example, say digitDuration=0.8s total per digit including gap. If an AudioBuffer for “5” is 0.5s long, we’ll add 0.3s silence. We schedule “5” at t = currentTimeOffset, and then set currentTimeOffset += 0.8. The next digit sound starts exactly 0.8s after the previous started. We do this for all parts. At the end, we schedule “Ende” and note the final time. All scheduling is done upfront before playback begins, so the sounds will play back-to-back seamlessly ￼. If “live” mode is off (pre-scripted message), we can schedule the entire sequence in one go. If “live” mode is on, we cannot pre-schedule unknown future input, so we instead schedule on the fly as described earlier, likely using a shorter lookahead.

Starting Playback: The user will click a “Play Transmission” button. In response, if the audio context is suspended (due to browser policy), we call audioCtx.resume() ￼. Then we build the schedule as above and start all source nodes. We likely also start a visual indicator or timer at this point (for example, the blinking LED or highlighting the current group on screen).

Stopping and Interrupting: It’s important to allow the user to stop playback mid-way (e.g., a “Stop” button). Once an AudioBufferSourceNode is started, it cannot be re-started or truly canceled (it can be stopped, but once stopped it can’t resume). To stop the whole transmission, one strategy is to keep track of all scheduled source nodes and call stop() on each one immediately; however, tracking dozens of nodes and stopping all is cumbersome. A simpler technique is to route all audio through a single GainNode, then disconnect that GainNode to instantly silence everything ￼. Specifically, we create a GainNode, connect all source nodes to that gain, and connect the gain to audioCtx.destination. When Stop is pressed, we can gain.disconnect() or set gain.value to 0. This effectively mutes and stops any further sound without needing to individually cancel nodes (the nodes will continue in background but output nothing audible, and will be garbage-collected after finishing) ￼ ￼. For a clean restart, we would also clear any queued scheduling or, if using a scheduling loop for live mode, clear the timers. On restart, we’ll create new AudioBufferSourceNodes as needed (since those can only be used once). The UI will reset (e.g., return the play button to “Play” state from “Stop” state).

Recording and WAV Export

One of the advanced requirements is to record the generated transmission audio and allow the user to download it as a WAV file. This can be achieved in a few ways:
	•	Real-time Recording with MediaRecorder: The Web Audio API allows us to create a MediaStreamAudioDestinationNode (via audioCtx.createMediaStreamDestination()) which acts like an output that can feed into the MediaStream API. We can connect our GainNode (or directly connect each source) to this MediaStream destination in addition to (or instead of) the regular speakers. This gives us a live audio stream of the transmission. Using the MediaRecorder API, we can record that stream as it plays ￼. The MediaRecorder will emit a Blob (likely audio/webm or audio/ogg depending on browser). We could then offer that blob for download. However, getting a WAV specifically might require conversion, as MediaRecorder doesn’t output WAV by default. One workaround is to record PCM data and construct a WAV file (which is what the next method effectively does).
	•	Offline Rendering to Buffer: Since our transmission is short and we have all audio data, we can use an OfflineAudioContext to render the audio fast and get an AudioBuffer of the result. We’d create an OfflineAudioContext with the desired length (duration of our transmission) and sample rate, schedule all the same AudioBuffer sources into it at the appropriate times (just like we did for real playback), and call offlineCtx.startRendering(). This will mix all the clips and produce one combined AudioBuffer containing the entire message audio. Once rendering finishes (which happens as fast as the CPU can mix it, faster than real-time), we get the PCM sample data via buffer.getChannelData(0) etc. ￼. We then manually construct a WAV file header and combine it with the PCM data bytes to form a WAV blob. There are examples of converting an AudioBuffer to WAV on StackOverflow ￼ ￼. Essentially, one must create a 44-byte header (RIFF chunk with size, WAVE format, fmt subchunk, data subchunk with length, etc.) and then append the 16-bit PCM samples. We can simplify by using an existing small library or code snippet (for example, Recorder.js’s offline encoding logic). In fact, one StackOverflow answer demonstrates using Recorder.js’s web worker to export a WAV in one go ￼ ￼ – we could embed a similar worker script. But to avoid external dependencies, we can write our own function to encode WAV since the format is straightforward PCM.

After obtaining the WAV blob (either via recording or offline rendering), the app will prompt the user to download it. This can be done by creating an object URL for the blob and linking it as a download anchor (e.g., “Download Transmission.wav”). Given this is a static app, all of this happens client-side; no server is needed.

Note: OfflineAudioContext approach has the advantage of not requiring the user to listen to the whole message to get the file; it generates the file instantly. However, it’s more complex to implement. The MediaRecorder approach is simpler but the user would have to either wait through playback or we run playback muted in background (which still takes real-time). For a first implementation, we might use MediaRecorder to capture live playback into a Blob, since it’s easier to implement and modern browsers support audio capture. If the output isn’t WAV, we can document that it will be webm or use an encoder for WAV. Either way, the feature will result in a downloadable audio file containing the spoken numbers message.

User Interface and Experience

The application’s UI will be designed to be intuitive and responsive, mimicking a simple numbers station “console”:

Layout and Responsiveness

The page will likely have a clean layout with sections for Message Input/Encoding, Playback Controls, and Dialer/Live Controls. For example:
	•	A top section for entering plaintext, selecting cipher options (radio buttons or a dropdown for A1Z26 vs Checkerboard, a checkbox for OTP, and if OTP then an input for key or a “Generate key” button), and a button to perform the encoding. The encoded output and group count can be displayed here, allowing the user to verify before playing. Possibly a small “plaintext vs ciphertext” toggle if they are decrypting or to show/hide the raw text.
	•	A section for XOR tool (this might be a collapsible panel or a separate tab, since it’s a distinct utility). It would have input areas for text/key, mode toggles, and output display. This keeps the XOR tool accessible without cluttering the main flow of the numbers station simulator.
	•	The Playback section with a voice pack selector (dropdown), and play/stop controls. We will also have buttons like “Play Message” and “Stop”, and maybe “Live Mode” toggle. Timing settings (if exposed to user) could be sliders or numeric inputs (for example, “Digit interval (ms)”, “Group pause (ms)”). If there are advanced options like adding background noise or LED, those can be toggles here.
	•	The Manual Dialer interface: This would show a keypad of buttons: digits 0-9 and the words “Achtung”, “Trennung”, “Ende”. It would resemble a telephone or military radio keypad. When the user clicks these buttons, the corresponding element is added to a transmission buffer (displayed on screen, maybe as a line of text showing what will be/has been transmitted). The app will also immediately play the corresponding audio if in live mode. If not in live mode, the dialer could function as a way to compose a message step by step: pressing “Achtung” adds that word, pressing digits adds those digits, etc., and one could then hit play to play the composed sequence. But primarily, it’s meant for a “live” feel, so likely we enable live mode when using the dialer. The dialer will be designed to be touch-friendly, with large buttons for mobile use. On mobile, the whole UI might reflow so that the keypad fills most of the screen when in use.
	•	Display elements: We will visually show the group count, maybe something like “Groups: 10” next to the output, and if possible, as the message plays, highlight the current group or show a progress (e.g., “Playing group 3 of 10”). If implementing an LED indicator, a small circle could blink red each time a digit is spoken or at a constant rate to simulate a transmitter light.

The design will use CSS Flexbox or Grid to rearrange elements on smaller screens. For instance, on desktop the input and output can be side by side, but on mobile, they might stack vertically. The keypad might scroll or become a modal on very small screens to ensure all buttons are accessible. We’ll use relative units and CSS media queries to achieve a mobile-responsive design.

Theming and Accessibility

A Dark Mode toggle will be provided to switch the color scheme to a dark background (as many radio and military UIs have black or green on black displays). This can be done by toggling a CSS class on the body (e.g., .dark-mode) which has corresponding styles (dark background, light text, etc.). Optionally, we could respect prefers-color-scheme and default to dark if the user’s system is in dark mode, but giving manual control is good. We’ll ensure sufficient contrast in both modes and use legible fonts (maybe a mono-space or segment display style font for the output, to resemble digital displays).

For accessibility, all interactive elements (buttons, selects) will be proper HTML elements for keyboard navigation and screen-reader labeling. The app’s functionality (except audio output) can be used without sound (e.g., the encoded message text is visible). However, the main point is audio, so we will at least provide text transcripts for the hearing impaired (the output groups are effectively the transcript).

Help and Info

We will include a Help section explaining the terminology and usage. This might be a modal dialog or an expandable panel that the user can open. It will cover:
	•	What Achtung, Trennung, Ende mean (e.g., “Achtung” means “Attention” – it marks the start of the message ￼. “Trennung” means “Separation” – used like “break” to separate parts of the message ￼. “Ende” means “End” – signifying the end of transmission ￼.).
	•	How to use the cipher options (with examples of A1Z26, OTP, etc., basically summarizing what we described but in more user-friendly terms).
	•	What the manual dialer does vs the automated message input.
	•	Possibly a note on the historical context of numbers stations (for interest) – e.g. “This simulator replicates the behavior of Cold War-era numbers stations. The format used here is inspired by the East German ‘Gongs’ station (Enigma G03) which used a female voice to read numbers after an “Achtung” preamble ￼.” This provides background and also justifies the presence of German words.

The help text will not assume prior knowledge, since part of the audience might be hobbyists or educators.

Session Load/Save (Advanced)

For convenience, the app can implement loading and saving of sessions. This means the user can save their current message, selected cipher settings, voice pack, and any other configuration into a JSON file, and later reload it to resume. A “Save Session” button would create a JSON blob containing for example:

{
  "message": "HELLO WORLD", 
  "cipher": "checkerboard", 
  "otpKey": "12345...", 
  "voicePack": "Spanish (Female)", 
  "repeatGroups": true, 
  "timing": {"digitMs":800,"groupPauseMs":1200}
}

We’ll prompt download of this JSON. Conversely, a “Load Session” file input can accept a JSON file and restore the settings (updating the UI fields accordingly). This feature is handy for experimenting with different settings or sharing a particular coded message with someone (they could load it and then play to hear it). Implementing this is straightforward with FileReader for input and URL.createObjectURL for download, and it works offline since it’s all client-side.

Technical Implementation Overview

The application will be structured in a modular way for clarity and maintainability. All code will be plain ES6+ JavaScript (no frameworks or build tools required, to keep it GH Pages friendly). We can use <script type="module"> to organize the code in multiple files (since modern static hosting supports modules). The core modules might include:
	•	MessageEncoder (or CipherEngine) Module: Responsible for text encoding/decoding. It will provide functions like encodeA1Z26(plaintext) returning a numeric string, encodeCheckerboard(plaintext, key) for the checkerboard (with possibly a default key built-in), and functions for applying OTP (applyOTP(numericStr, keyStr) for mod-10 addition) and removing OTP. It can also handle formatting into groups (formatGroups(numericStr, groupSize) returning an array of groups and maybe perform padding). Essentially, this module turns plaintext into ready-to-transmit digit groups and can do the reverse if needed (to support decoding mode). We’ll keep this logic separate from UI so it can be unit-tested or extended easily.
	•	XORCipher Module: Implements the XOR encrypt/decrypt utility. This can be separate or part of CipherEngine, but logically it’s a different domain (binary/hex vs number station). It will have xorAscii(text, key) and xorHex(hexString, keyHex) functions. Possibly a helper to convert between hex and Uint8Array and between text and Uint8Array. This module is utilized by the XOR tool part of the UI.
	•	AudioPlayer (or TransmissionPlayer) Module: This will manage loading audio and playing the message. It likely maintains the AudioContext and lists of AudioBuffers. Key methods could be loadVoicePack(packName) which reads the config (paths) and loads all necessary files (returns a Promise when done). Also methods like scheduleMessagePlayback(groups, repeatGroups, groupCount, voicePack) which prepares the audio nodes as described in Playback section and starts them. It can also expose controls to stopPlayback() and maybe playLiveDigit(digitOrWord) for live mode (which schedules or plays immediately the given sound). Timing parameters would be properties of this module or passed in. We might also include the MediaRecorder or Offline rendering logic here as recordMessageToWav(groups) that either initiates MediaRecorder or runs OfflineContext as discussed. Essentially, AudioPlayer abstracts the low-level Web Audio details from the rest of the app.
	•	UI Module (main script): This will tie everything together. It will handle DOM events: e.g., when the user clicks “Encode”, it uses MessageEncoder to encode the plaintext and displays the result. When “Play” is clicked, it asks AudioPlayer to play the current message with the current settings. The voice pack selection change triggers AudioPlayer to load that pack. The dialer buttons when clicked will call AudioPlayer to play the sound (if live) and update the display buffer. The UI module also handles toggling dark mode (by adding/removing the .dark class on <body>), opening the help modal, and so on. We’ll ensure to update interface elements at appropriate times (e.g., disable the Play button while audio is playing, or change it to a “Pause/Stop” button, etc., for clarity).
	•	Preloader: We might implement a small preloader for assets – for example, show a “Loading voice pack…” message or progress bar while the WAV files are being fetched and decoded. The AudioPlayer can expose an event or promise for when loading is complete so the UI can remove any loading indicator. Given everything is local on GH Pages and file sizes are small, loading should be quick, but it’s good to handle it gracefully.

All assets (HTML, CSS, JS, WAV files) will be referred with relative paths so they work on GitHub Pages. There’s no need for external CDN or APIs.

The code will be well-commented to explain each part, facilitating future expansion or modification. For instance, we can comment the encoding logic to cite the source of the cipher method, and comment the Audio scheduling logic to note why we choose a certain approach (e.g., “using GainNode for stop-all functionality as suggested by Web Audio best practices ￼” in code comments).

Performance-wise, the tasks (encoding text, scheduling audio) are trivial for modern browsers given the short message lengths and small audio files. Even the OfflineAudioContext rendering of a few seconds of audio is fine. We just need to be mindful of memory if someone tries to spam extremely long messages (but one-time-pad pages historically limited messages to a few hundred groups max). We could impose a reasonable limit (maybe 100 groups or so) to avoid huge audio scheduling.

Advanced Feature Implementation

Finally, touching on the advanced features:
	•	Background Noise: We can simulate a shortwave radio background hiss by generating white noise and playing it softly under the message. Using the Web Audio API, we’ll create a continuous noise AudioBuffer. For example, we create 1 second of stereo noise: for each sample, set a random value between -1 and 1 ￼, and then set this buffer to loop. Connect it to a GainNode with a low gain (so it’s a quiet hiss under the voice). When the transmission starts, start the noise buffer node at the same time (or slightly before) and stop it at the end. Alternatively, we can pre-generate a 30-second noise clip from an actual shortwave recording for authenticity and loop it. In the UI, a “Static Noise” toggle will enable/disable this effect. The static just adds realism; the core message audio is unaffected by it (the gain is separate and just mixes into the output).
	•	Blinking LED: We will create a small circular <div id="led"> styled as a red or green LED. When the transmission is in progress, we can blink it. Easiest is to use CSS animation: e.g., add a class .blinking that has animation: blink 1s infinite alternate (with @keyframes toggling opacity from 0 to 1). But that would blink at a fixed rate. For a more synchronized blink (say blink per group or per second of transmission), we can do it via JS: e.g., on each group boundary, toggle the LED class quickly. However, a fixed-rate blink is also acceptable as a “transmit” indicator. We will turn on the blinking when playback starts and turn it off when done or stopped. This is a cosmetic UI feature, but it enhances the “radio operator” vibe.
	•	Message Repeat or Multiple Messages: If needed, we can allow inputting multiple messages (like a schedule of messages). Some stations would send multiple different messages one after another. Our app could allow the user to encode several texts and queue them. But this is likely out of scope unless specifically asked. Instead, we might implement a simple “repeat message twice” checkbox which, if checked, will play the whole message, then a pause, then “Achtung” and message again, etc., or simply repeat the groups as in some formats. This overlaps with group repeat option we have. We will document whatever repeating functionality we include (group repeat or full repeat).

The entire application will run offline. Once the page and assets are loaded from GitHub Pages, no internet connection is needed. All encryption/decryption and audio playback is done in-browser. This makes it not only hostable on static pages but also usable in e.g. a portable setting (just open the file).

In summary, this web app will provide a comprehensive simulation of a numbers station transmission. It converts user messages into 5-digit cipher groups using classic methods, then broadcasts them with accurate audio timing using multiple language voice packs. The UI will be user-friendly and educational, including explanations for the special terms and giving control over playback and encryption settings. By organizing code into logical modules and preloading assets, we ensure smooth performance. With advanced options like noise, blinking LED, and session saving, the simulation will feel realistic and be fun to use, all while being entirely static and self-contained.

Sources:
	•	Priyom.org – G03 “Gongs” number station format ￼
	•	WAR10CK (StackExchange) – Explanation of “Achtung [ID] Trennung [Count] … Ende” format ￼
	•	Crypto Corner – Straddling checkerboard cipher overview ￼
	•	Catencode – A1Z26 cipher example (“HELLO” → “8 5 12 12 15”) ￼
	•	Cryptools XORCipher – XOR encryption example and properties ￼ ￼
	•	Cryptography StackExchange – One-time pad mod 10 arithmetic (each digit modulo 10) ￼
	•	MDN Web Audio API – Best practices for buffering short sounds ￼ ￼
	•	MDN AudioBuffer – Generating white noise example ￼
	•	StackOverflow – Using GainNode to stop all scheduled Web Audio at once ￼
	•	“The Postface” Blog – Gerät 32620 (Stasi speech generator) info on voice clips (0–9, Achtung, Trennung, Ende) ￼